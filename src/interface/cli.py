import argparse
import sys
import asyncio
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

from ..graph.workflow import create_graph
from ..core.storage import StorageManager
from ..core.models.timeline import Timeline
from ..core.models.evidence import Evidence
from ..core.models.comments import CommentScore
from ..core.models.strategy import SearchStrategy
from ..agents.report_writer import write_narrative_report

def _render_report(
    topic: str,
    timeline: Timeline,
    evidences: List[Evidence],
    comment_scores: List[CommentScore],
    stats: Dict[str, Any]
) -> str:
    """ç”Ÿæˆ Markdown æ ¼å¼çš„æœ€ç»ˆæŠ¥å‘Š"""
    
    # 1. æ ‡é¢˜ä¸å…ƒæ•°æ®
    report = f"# DeepTrace è°ƒæŸ¥æŠ¥å‘Šï¼š{topic}\n\n"
    report += f"- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
    report += f"- **è¯æ®æ•°é‡**: {stats['evidence_count']}\n"
    report += f"- **äº‹ä»¶æ•°é‡**: {stats['event_count']}\n"
    report += f"- **æ£€ç´¢è½®æ¬¡**: {stats['loops']}\n\n"
    
    # 2. æ—¶é—´çº¿
    report += "## ğŸ“… äº‹ä»¶æ—¶é—´çº¿\n\n"
    if timeline and timeline.events:
        for event in timeline.events:
            time_str = event.time.strftime('%Y-%m-%d %H:%M') if event.time else "æ—¶é—´æœªçŸ¥"
            report += f"### {time_str} - {event.title}\n"
            if event.source:
                report += f"- **æ¥æº**: {event.source}\n"
            report += f"- **æ‘˜è¦**: {event.description}\n"
            report += f"- **ç½®ä¿¡åº¦**: {event.confidence:.2f} ({event.status.value})\n"
            if event.evidence_ids:
                report += "- **æ”¯æŒè¯æ®**:\n"
                # ç®€å•æŸ¥æ‰¾è¯æ®æ¥æº
                related_evs = [e for e in evidences if e.id in event.evidence_ids]
                for rev in related_evs:
                    source_name = rev.source.value if hasattr(rev.source, 'value') else str(rev.source)
                    # ä¼˜å…ˆæ˜¾ç¤º URL é“¾æ¥ï¼Œå¦‚æœæ²¡æœ‰ URL åˆ™æ˜¾ç¤ºç®€çŸ­æ‘˜è¦
                    if rev.url:
                        # Markdown é“¾æ¥æ ¼å¼ï¼š[æ¥æº](URL)
                        report += f"  - [{source_name}]({rev.url})\n"
                    else:
                        # é™çº§ï¼šæ˜¾ç¤ºå†…å®¹æ‘˜è¦
                        content_preview = rev.content[:50] + "..." if len(rev.content) > 50 else rev.content
                        report += f"  - [{source_name}] {content_preview}\n"
            report += "\n"
    else:
        report += "ï¼ˆæœªç”Ÿæˆæœ‰æ•ˆæ—¶é—´çº¿ï¼‰\n\n"
        
    # 3. å…³é”®è¯„è®º
    if comment_scores:
        report += "## ğŸ’¬ å…³é”®èˆ†æƒ…çº¿ç´¢\n\n"
        top_scores = sorted(comment_scores, key=lambda x: x.total_score, reverse=True)[:5]
        
        # æ„å»ºè¯„è®ºå†…å®¹æ˜ å°„
        comment_map = {}
        promoted_comment_ids = set()
        for ev in evidences:
            if ev.comments:
                for c in ev.comments:
                    comment_map[c.id] = c
            if ev.metadata.get("origin") == "comment_promotion":
                promoted_comment_ids.add(ev.metadata.get("comment_id"))
        
        for i, score in enumerate(top_scores, 1):
            comment = comment_map.get(score.comment_id)
            if comment:
                is_promoted = score.comment_id in promoted_comment_ids
                mark = "âœ¨ [å·²æ™‹å‡ä¸ºè¯æ®]" if is_promoted else ""
                report += f"### {i}. [{score.total_score:.2f}] {comment.author}\n"
                report += f"> {comment.content}\n\n"
                report += f"- **åˆ†æ**: {score.rationale}\n"
                report += f"- **çŠ¶æ€**: {mark}\n\n"

    # 4. å¾…è§£ç–‘ç‚¹
    if timeline and timeline.open_questions:
        report += "## â“ å¾…è§£ç–‘ç‚¹ (Open Questions)\n\n"
        for q in timeline.open_questions:
            report += f"- **[{q.id}]** {q.question}\n"
    
    return report

async def run_analysis(query: str, strategy: Optional[str] = None, depth: Optional[str] = None):
    """
    è¿è¡Œå®Œæ•´çš„äº‹ä»¶é“¾åˆ†ææµç¨‹ï¼ˆåŸºäº LangGraphï¼‰ã€‚
    
    Args:
        query: äº‹ä»¶æŸ¥è¯¢å…³é”®è¯
        strategy: æ£€ç´¢ç­–ç•¥ (generic/weibo/xhs/mixed)
        depth: è¯æ®æŠ“å–æ·±åº¦ (quick/balanced/deep)
    """
    print(f"ğŸ” æ­£åœ¨åˆ†æäº‹ä»¶: {query}")
    print("=" * 60)
    
    # åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨
    storage = StorageManager()
    start_time = datetime.now()
    run_dir = storage.start_run(query)
    print(f"[DeepTrace] Run directory created: {run_dir}")
    
    # åˆå§‹åŒ–å›¾
    app = create_graph()
    
    # åˆå§‹åŒ–çŠ¶æ€
    config = {
        "max_loops": 3,
        "model_name": "qwen-2.5-32b" # ç¤ºä¾‹é…ç½®
    }
    
    initial_state = {
        "initial_query": query,
        "current_query": query,
        "loop_step": 0,
        "max_loops": config["max_loops"]
    }
    
    # å¦‚æœæŒ‡å®šäº†ç­–ç•¥ï¼Œé¢„è®¾åˆ° initial_state
    if strategy:
        strategy_map = {
            "generic": SearchStrategy.GENERIC,
            "weibo": SearchStrategy.WEIBO,
            "xhs": SearchStrategy.XHS,
            "mixed": SearchStrategy.MIXED,
        }
        if strategy.lower() in strategy_map:
            initial_state["search_strategy"] = strategy_map[strategy.lower()]
            print(f"ğŸ“Œ ç­–ç•¥å·²æ‰‹åŠ¨æŒ‡å®š: {strategy.upper()}")
    
    # å¦‚æœæŒ‡å®šäº†è¯æ®æ·±åº¦ï¼Œé¢„è®¾åˆ° initial_state
    if depth:
        if depth.lower() in ["quick", "balanced", "deep"]:
            initial_state["evidence_depth"] = depth.lower()
            print(f"ğŸ“Š è¯æ®æ·±åº¦å·²æ‰‹åŠ¨æŒ‡å®š: {depth.upper()}")
    
    # æ‰§è¡Œå›¾
    try:
        state = await app.ainvoke(initial_state, config={"recursion_limit": 100})
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return

    # è·å–ç»“æœ
    steps = state.get("steps", [])
    timeline = state.get("timeline") or Timeline(events=[], open_questions=[])
    comment_scores = state.get("comment_scores", [])
    evidences = state.get("evidences", [])
    claims = state.get("claims", [])
    
    # æ‰“å°æ‰§è¡Œæ­¥éª¤
    print("\n[æ‰§è¡Œè½¨è¿¹]")
    for step in steps:
        print(f"  ğŸ‘‰ {step}")
        
    # æ‰“å°å…³é”®è¯„è®º (æ§åˆ¶å°ç®€ç•¥ç‰ˆ)
    if comment_scores:
        print("\n[å…³é”®è¯„è®ºæŒ–æ˜]")
        print("=" * 60)
        top_scores = sorted(comment_scores, key=lambda x: x.total_score, reverse=True)[:5]
        # ... (æ­¤å¤„çœç•¥æ§åˆ¶å°è¯¦ç»†æ‰“å°ï¼Œä¸»è¦ä¾é  Report)
        print(f"å·²è¯†åˆ« {len(comment_scores)} æ¡é«˜ä»·å€¼è¯„è®ºï¼Œè¯¦æƒ…è¯·è§æŠ¥å‘Šã€‚")
    
    # æ‰“å°æœ€ç»ˆæŠ¥å‘Š (æ§åˆ¶å°ç®€ç•¥ç‰ˆ)
    print("\n[ç”ŸæˆæŠ¥å‘Š]")
    print("=" * 60)
    if timeline.events:
        print(timeline.to_markdown())
    else:
        print("âš ï¸  æœªèƒ½ç”Ÿæˆæ—¶é—´çº¿æŠ¥å‘Š")
    print("=" * 60)
    
    # --- å­˜å‚¨é€»è¾‘ ---
    end_time = datetime.now()
    stats = {
        "evidence_count": len(evidences),
        "event_count": len(timeline.events),
        "loops": state.get("loop_step", 0),
    }
    
    # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
    report_md = _render_report(query, timeline, evidences, comment_scores, stats)
    
    # ä¿å­˜æ‰€æœ‰æ–‡ä»¶
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœåˆ°: {run_dir}")
    storage.save_meta(
        run_dir,
        topic=query,
        start_time=start_time,
        end_time=end_time,
        model=config["model_name"],
        config=config,
        stats=stats
    )
    if timeline:
        storage.save_timeline(run_dir, timeline)
    storage.save_evidences(run_dir, evidences)
    storage.save_report(run_dir, report_md)
    
    # ç”Ÿæˆå™äº‹æ€§æŠ¥å‘Š
    print(f"\nğŸ“ æ­£åœ¨ç”Ÿæˆå™äº‹æ€§è°ƒæŸ¥æŠ¥å‘Š...")
    narrative_report_md = await write_narrative_report(query, timeline, evidences, claims=claims)
    (run_dir / "narrative_report.md").write_text(narrative_report_md, encoding="utf-8")
    
    print(f"âœ… åˆ†æå®Œæˆï¼")
    print(f"   - ç»“æ„åŒ–æŠ¥å‘Š: {run_dir / 'report.md'}")
    print(f"   - è°ƒæŸ¥æŠ¥å‘Šæ–‡ç« : {run_dir / 'narrative_report.md'}")

def main():
    parser = argparse.ArgumentParser(
        description="DeepTrace Event Chain Investigator CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python -m src.interface.cli --query "ç¿»è½¦"
  python -m src.interface.cli --query "DeepSeek" --strategy mixed
  python -m src.interface.cli --query "iPhoneæµ‹è¯„" --strategy xhs
        """
    )
    parser.add_argument(
        "--query", 
        type=str, 
        required=True, 
        help="äº‹ä»¶æŸ¥è¯¢å…³é”®è¯ï¼ˆå¦‚ï¼š'ç¿»è½¦'ã€'äº§å“é—®é¢˜'ï¼‰"
    )
    parser.add_argument(
        "--strategy",
        type=str,
        choices=["generic", "weibo", "xhs", "mixed"],
        default=None,
        help="æ£€ç´¢ç­–ç•¥: generic(é€šç”¨æœç´¢), weibo(å¾®åšä¸“é¡¹), xhs(å°çº¢ä¹¦ä¸“é¡¹), mixed(æ··åˆæ¨¡å¼)ã€‚ä¸æŒ‡å®šåˆ™ç”±AIè‡ªåŠ¨å†³ç­–ã€‚"
    )
    parser.add_argument(
        "--depth",
        type=str,
        choices=["quick", "balanced", "deep"],
        default=None,
        help="è¯æ®æŠ“å–æ·±åº¦: quick(5æ¡ç»“æœ), balanced(10æ¡ç»“æœ), deep(15æ¡ç»“æœ)ã€‚ä¸æŒ‡å®šåˆ™ç”±AIè‡ªåŠ¨å†³ç­–ã€‚"
    )
    
    args = parser.parse_args()
    
    # Windows å…¼å®¹æ€§å¤„ç†
    if sys.platform == "win32":
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        # å¼ºåˆ¶è®¾ç½® stdout ç¼–ç ä¸º utf-8
        sys.stdout.reconfigure(encoding='utf-8')
        
    asyncio.run(run_analysis(args.query, args.strategy, args.depth))

if __name__ == "__main__":
    main()
